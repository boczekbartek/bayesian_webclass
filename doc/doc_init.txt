Zadanie 1 - automatyczny klasyfikator stron internetowych

Aplikacja do klasyfikacji stron internetowych bazująca na ich treści. Utworzyć zbiór stron trenujących i wykorzystać wybrany klasyfikator (np. Naiwny klasyfikator Bayesowski z biblioteki faif). Atrybutami mogą być wybrane wyrazy, znaczenia wyrazów utworzone z Wikipedii lub inne.


Materiały pomocnicze:
https://web.stanford.edu/class/cs124/lec/naivebayes.pdf
http://software.ucv.ro/~cmihaescu/ro/teaching/AIR/docs/Lab4-NaiveBayes.pdf
http://nlp.stanford.edu/IR-book/pdf/irbookonlinereading.pdf
https://www.analyticsvidhya.com/blog/2015/09/naive-bayes-explained/
http://www.iaeng.org/publication/IMECS2012/IMECS2012_pp519-523.pdf
https://arxiv.org/pdf/1406.5616.pdf
http://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=4142381

Proponowany zbiór danych:
1. https://dms.sztaki.hu/en/letoltes/ecmlpkdd-2010-discovery-challenge-data-set
2. ?
~3. https://archive.ics.uci.edu/ml/datasets/Phishing+Websites

Proponowane środowisko instalacji:
CMake pod przykryciem catkin/catkin_tools/ament

Proponowana kontrola wersji:
git z wykorzystaniem github'a

Proponowana realizacja:
C++ z wykorzystaniem bibliotek boost, libcurl, libxml, libtidy, Python(Django) oraz ew. wykorzystanie PostgreSQL




                            AUTOMATYCZNY KLASYFIKATOR STRON INTERNETOWYCH


1.  Temat:
        Aplikacja do klasyfikacji stron internetowych bazująca na ich treści. Utworzyć zbiór stron trenujących i wykorzystać wybrany klasyfikator. Atrybutami mogą być wybrane wyrazy, znaczenia wyrazó utworzone z Wikipedii lub inne.

2.  Opis docelowej realizacji:
        Realizacja klasyfikatora planowana jest z wykorzystaniem biblioteki faif i zawartego w niej naiwnego klasyfikatora Bayesa. Klasyfikator zostanie wytrenowany na zadanym zbiorze danych, a następnie zademonstrowana zostanie jego zdolność do klasyfikacji stron internetowych w oparciu o wartości atrybutów wnioskowane z wybranych części kodu html(np. tytułów, nagłówków, podpisów pod zdjęciami etc.).

3. Docelowa funkcjonalność:
        - Interfejs umożliwiający wczytywanie zadanych stron do programu (proponowane jest tutaj wykorzystanie biblioteki libcurl).
        - Interfejs wykorzystujący istniejące biblioteki (np. libtidy w połączeniu z libxml) bądź proste wyrażenia regularne w celu oczyszczenia kodu html, analizy składni i końcowo ekstrakcji wartości zadanych atrybutów z rozpatrywanej strony.
        - Interfejs wykorzystujący naiwny klasyfikator Bayesa do analizy atrybutów i przypisania rozpatrywanego zbioru stron do jednej z zadanych kategorii.
        - Aplikacja graficzna.
        - Wykorzystanie plików tekstowych (np. .xml) do zapisywania konfiguracji klasyfikatora w przejrzysty sposób.

4. Proponowana funkcjonalność dodatkowa:
        - Dodatkowy program analizujący działanie klasyfikatora i prezentujący w formie tekstowej bądź graficznej np. dane o ilości poprawnych/niepoprawnych klasyfikacji czy wielkościach użytych zbiorów.
        - Dodatkowy interfejs wykorzystujący implementację bardziej zaawansowanego klasyfikatora TAN Bayes w języku R i umożliwiający porównanie obu klasyfikatorów (np. różnic w czasie pracy, ilości użytych zasobów czy poprawności klasyfikacji).
        - Przeprowadzenie dodatkowej analizy porównującej działanie obu klasyfikatorów na różnych typach zbiorów(bądź podzbiorów) danych, np. różnice między klasyfikacją ogólną (strony edukacyjne, sportowe, informacyjne etc.), a klasyfikacją szczegółową (strony o fizyce molekularnej, fizyce atomowej, fizyce klasycznej etc.
